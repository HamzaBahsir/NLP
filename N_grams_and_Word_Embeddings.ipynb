{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamzaBahsir/NLP/blob/main/N_grams_and_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mea-CemjMt15"
      },
      "source": [
        "# **N-grams and Word Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUPIYDoTM3yo"
      },
      "source": [
        "# **Objectives:**\n",
        "\n",
        "Here we will do fundamental techniques for representing text in a machine-readable format. These techniques form the foundation for various NLP applications, enabling machines to understand and process human language efficiently.\n",
        "\n",
        "1. N-gram Models\n",
        "    * Unigram\n",
        "    * Bigrams\n",
        "    * Trigrams\n",
        "2. Word Embeddings\n",
        "  * Word2Vec\n",
        "      * Continuous Bag-of-Words (CBOW)\n",
        "      * Skip-gram\n",
        "  * Global Vectors for Word Representation (GloVe)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Extra Resources**\n",
        "[Natural Language Processing with Python](https://www.nltk.org/book/)"
      ],
      "metadata": {
        "id": "siK_BV526xua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Libraries Required**\n",
        "\n",
        "* nltk\n",
        "* gensim\n",
        "* os\n",
        "* platform\n",
        "* sys\n",
        "* struct\n",
        "* numpy\n",
        "* scipy\n",
        "* gensim\n"
      ],
      "metadata": {
        "id": "DwpwhpgM60JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# For N-gram\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.probability import FreqDist\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMI7-PGt7Ehm",
        "outputId": "8fb445a7-6533-43ac-c811-7b372393ced1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text preparation**"
      ],
      "metadata": {
        "id": "ycrSkYocBj4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"Natural Language Processing is an exciting field. NVDEE is provide services in this field.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hVQVXNYUcWx",
        "outputId": "0be62071-f1ea-454d-e7e4-f2306bee3296"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', 'is', 'an', 'exciting', 'field', '.', 'NVDEE', 'is', 'provide', 'services', 'in', 'this', 'field', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unigrams**"
      ],
      "metadata": {
        "id": "jxp9HW-5-scg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate unigrams (1-grams)\n",
        "unigrams = list(ngrams(tokens, 1))\n",
        "print(\"Unigrams:\", unigrams)\n",
        "\n",
        "\n",
        "# Calculate frequency distribution\n",
        "unigram_freq_dist = FreqDist(unigrams)\n",
        "\n",
        "# Output the frequency of each unigram\n",
        "print(\"\\nUnigrams : Frequency\")\n",
        "for unigrams, frequency in unigram_freq_dist.items():\n",
        "    print(f\"{unigrams}: {frequency}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9fDQkBS-ddN",
        "outputId": "3bde8272-007b-401b-f9d1-27bf8e6608f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: [('Natural',), ('Language',), ('Processing',), ('is',), ('an',), ('exciting',), ('field',), ('.',), ('NVDEE',), ('is',), ('provide',), ('services',), ('in',), ('this',), ('field',), ('.',)]\n",
            "\n",
            "Unigrams : Frequency\n",
            "('Natural',): 1\n",
            "('Language',): 1\n",
            "('Processing',): 1\n",
            "('is',): 2\n",
            "('an',): 1\n",
            "('exciting',): 1\n",
            "('field',): 2\n",
            "('.',): 2\n",
            "('NVDEE',): 1\n",
            "('provide',): 1\n",
            "('services',): 1\n",
            "('in',): 1\n",
            "('this',): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total tokens\n",
        "total_tokens = len(tokens) # Here this is equal to sum of frequencies of unigrams, which is why it is used to compute probabilities.\n",
        "\n",
        "# Convert frequencies to probabilities\n",
        "unigram_prob_dist = {unigram: count / total_tokens for unigram, count in unigram_freq_dist.items()}\n",
        "\n",
        "# Print probabilities\n",
        "print(\"Unigram : Probability\")\n",
        "for unigram, prob in unigram_prob_dist.items():\n",
        "    print(f\"{unigram}: {prob:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldEkV5ArTMzm",
        "outputId": "c77d13c5-b525-4f7e-ea20-e44a7c0e569e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram : Probability\n",
            "('Natural',): 0.062\n",
            "('Language',): 0.062\n",
            "('Processing',): 0.062\n",
            "('is',): 0.125\n",
            "('an',): 0.062\n",
            "('exciting',): 0.062\n",
            "('field',): 0.125\n",
            "('.',): 0.125\n",
            "('NVDEE',): 0.062\n",
            "('provide',): 0.062\n",
            "('services',): 0.062\n",
            "('in',): 0.062\n",
            "('this',): 0.062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(unigram_prob_dist, top_n=3):\n",
        "    # Sort words by probability (descending)\n",
        "    sorted_words = sorted(unigram_prob_dist.items(), key=lambda x: -x[1])\n",
        "    # Return top N words\n",
        "    return [word for word, prob in sorted_words[:top_n]]\n",
        "\n",
        "# Example usage\n",
        "top_words = predict_next_word(unigram_prob_dist, top_n=3)\n",
        "print(\"Top Predictions (Context Ignored):\", top_words)\n",
        "\n",
        "# Prediction Example: Predict after \"Natural\"\n",
        "context = [\"Natural\"]\n",
        "prediction = predict_next_word(unigram_prob_dist)\n",
        "print(f\"\\nAfter '{context[-1]}':\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9LO5KH5ZfYN",
        "outputId": "5378f0ad-11bc-4c09-c52a-bede52ab065f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Predictions (Context Ignored): [('is',), ('field',), ('.',)]\n",
            "\n",
            "After 'Natural': [('is',), ('field',), ('.',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bigrams**"
      ],
      "metadata": {
        "id": "zHT-IWFCghyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate bigrams (2-grams)\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "print(\"Bigrams:\", bigrams)\n",
        "\n",
        "\n",
        "# Calculate frequency distribution\n",
        "bigram_freq_dist = FreqDist(bigrams)\n",
        "\n",
        "# Output the frequency of each bigram\n",
        "print(\"\\nBigrams : Frequency\")\n",
        "for bigram, frequency in bigram_freq_dist.items():\n",
        "    print(f\"{bigram}: {frequency}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O_el8r6oqxh",
        "outputId": "61976b2c-466c-4841-d648-d784ce89847b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams: [('Natural', 'Language'), ('Language', 'Processing'), ('Processing', 'is'), ('is', 'an'), ('an', 'exciting'), ('exciting', 'field'), ('field', '.'), ('.', 'NVDEE'), ('NVDEE', 'is'), ('is', 'provide'), ('provide', 'services'), ('services', 'in'), ('in', 'this'), ('this', 'field'), ('field', '.')]\n",
            "\n",
            "Bigrams : Frequency\n",
            "('Natural', 'Language'): 1\n",
            "('Language', 'Processing'): 1\n",
            "('Processing', 'is'): 1\n",
            "('is', 'an'): 1\n",
            "('an', 'exciting'): 1\n",
            "('exciting', 'field'): 1\n",
            "('field', '.'): 2\n",
            "('.', 'NVDEE'): 1\n",
            "('NVDEE', 'is'): 1\n",
            "('is', 'provide'): 1\n",
            "('provide', 'services'): 1\n",
            "('services', 'in'): 1\n",
            "('in', 'this'): 1\n",
            "('this', 'field'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trigrams**"
      ],
      "metadata": {
        "id": "Kxv-yFrSgWT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Trigrams (3-grams) on the same sample text (used in Unigrams/Bigrams)\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "print(\"Trigrams:\", trigrams)\n",
        "\n",
        "# Calculate frequency distribution of Trigrams\n",
        "trigram_freq_dist = FreqDist(trigrams)\n",
        "\n",
        "\n",
        "# Output the frequency along with the trigram\n",
        "print(\"\\nTrigram : Frequency\")\n",
        "for trigram, frequency in trigram_freq_dist.items():\n",
        "    print(f\"{trigram}: {frequency}\")\n"
      ],
      "metadata": {
        "id": "AVp7HDHt5eBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86cbf605-3edc-4032-c0ae-3d0f676b8dfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigrams: [('Natural', 'Language', 'Processing'), ('Language', 'Processing', 'is'), ('Processing', 'is', 'an'), ('is', 'an', 'exciting'), ('an', 'exciting', 'field'), ('exciting', 'field', '.'), ('field', '.', 'NVDEE'), ('.', 'NVDEE', 'is'), ('NVDEE', 'is', 'provide'), ('is', 'provide', 'services'), ('provide', 'services', 'in'), ('services', 'in', 'this'), ('in', 'this', 'field'), ('this', 'field', '.')]\n",
            "\n",
            "Trigram : Frequency\n",
            "('Natural', 'Language', 'Processing'): 1\n",
            "('Language', 'Processing', 'is'): 1\n",
            "('Processing', 'is', 'an'): 1\n",
            "('is', 'an', 'exciting'): 1\n",
            "('an', 'exciting', 'field'): 1\n",
            "('exciting', 'field', '.'): 1\n",
            "('field', '.', 'NVDEE'): 1\n",
            "('.', 'NVDEE', 'is'): 1\n",
            "('NVDEE', 'is', 'provide'): 1\n",
            "('is', 'provide', 'services'): 1\n",
            "('provide', 'services', 'in'): 1\n",
            "('services', 'in', 'this'): 1\n",
            "('in', 'this', 'field'): 1\n",
            "('this', 'field', '.'): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word2Vec**"
      ],
      "metadata": {
        "id": "dTuh2rAT-Zfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install latest version of gensim\n",
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss4Ayw5x6wYe",
        "outputId": "7e0f0707-d315-4720-aef9-fbc547dc9cac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the installation, a manual Colab Session Restart is required to fetch updated packages. It can be done by either of the two options given below:\n",
        "\n",
        "\n",
        "1.   **Runtime -> Restart Session** (or using the shortcut `Ctrl + M + .`)\n",
        "2.   To avoid Manually Restarting the Session, **Run the next Code Block** to kill and auto restart the session\n",
        "\n"
      ],
      "metadata": {
        "id": "EOJh67v_9yiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "dhosQIox-j3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After successfully restarting the session, run the following code to ensure proper installation and import. (It will give errors if the session is not restarted!)"
      ],
      "metadata": {
        "id": "txvh4tJL-7CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks to ensure Gensim is installed correctly along with correct version of dependencies\n",
        "import platform; print(platform.platform())\n",
        "import sys; print(\"Python\", sys.version)\n",
        "import struct; print(\"Bits\", 8 * struct.calcsize(\"P\"))\n",
        "import numpy; print(\"NumPy\", numpy.__version__)\n",
        "import scipy; print(\"SciPy\", scipy.__version__)\n",
        "import gensim; print(\"gensim\", gensim.__version__)\n",
        "from gensim.models import word2vec; print(\"FAST_VERSION\", word2vec.FAST_VERSION)\n",
        "## For downloading data from wiki to analyze\n",
        "import gensim.downloader as api\n",
        "# For data preparation\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-lbGXHi7A2w",
        "outputId": "a940e6d1-f6a3-46e7-e559-fc28f4e2f3e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "Python 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n",
            "Bits 64\n",
            "NumPy 1.26.4\n",
            "SciPy 1.13.1\n",
            "gensim 4.3.3\n",
            "FAST_VERSION 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get back to training our Word2Vec models"
      ],
      "metadata": {
        "id": "ii-oMqkk_SRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Text preparation**"
      ],
      "metadata": {
        "id": "xJLiVBJbCDoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences as a lists\n",
        "sentences = [\n",
        "    \"Natural language processing is fascinating\",\n",
        "    \"Word embeddings capture semantic relationships\",\n",
        "    \"CBOW and SkipGram are popular models\",\n",
        "    \"Word2Vec is a technique for learning vector representations\",\n",
        "    \"SkipGram tends to perform better on rare words\",\n",
        "    \"CBOW is faster and more efficient for common words\"\n",
        "]\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sent.lower()) for sent in sentences]\n",
        "print(tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO1rhIqNUZUa",
        "outputId": "b732a85a-533c-46d2-d060-d4fbb15b62f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['natural', 'language', 'processing', 'is', 'fascinating'], ['word', 'embeddings', 'capture', 'semantic', 'relationships'], ['cbow', 'and', 'skipgram', 'are', 'popular', 'models'], ['word2vec', 'is', 'a', 'technique', 'for', 'learning', 'vector', 'representations'], ['skipgram', 'tends', 'to', 'perform', 'better', 'on', 'rare', 'words'], ['cbow', 'is', 'faster', 'and', 'more', 'efficient', 'for', 'common', 'words']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Number of CPU cores (Colab free: 2x CPUs) to set num of workers\n",
        "# !cat /proc/cpuinfo\n",
        "print(\"CPU Cores:\")\n",
        "!grep -c '^processor' /proc/cpuinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uqup7PL9Mju",
        "outputId": "bff38b42-c6cd-444a-fc3b-5c5d9beb5f4b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Cores:\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Continuous Bag-of-Words (CBOW)**\n",
        "\n",
        "CBOW predicts a word from its context. It can be used by setting `sg=0` in `gensim.models.Word2Vec()`"
      ],
      "metadata": {
        "id": "J6fxUpX-9Um2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Option 1: Train a Word2Vec model using CBOW (sg=0)\n",
        "# ---------------------\n",
        "cbow_model = Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=100,    # Dimensionality of word vectors\n",
        "    window=5,           # Maximum distance between current and predicted word\n",
        "    sg=0,               # CBOW architecture (default)\n",
        "    min_count=1,        # Ignore words with frequency < min_count\n",
        "    workers=2           # Number of CPU threads\n",
        ")\n",
        "\n",
        "print(\"CBOW Vector for 'language':\")\n",
        "print(cbow_model.wv['language'])\n",
        "\n",
        "print(\"\\nCBOW Model - Most similar words to 'language':\")\n",
        "print(cbow_model.wv.most_similar(\"language\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpX7ynuOvADs",
        "outputId": "1e0340db-df48-4842-acc0-340068bc4fea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBOW Vector for 'language':\n",
            "[ 6.4154328e-03 -8.9511415e-03 -7.3454725e-03 -1.7511440e-03\n",
            "  1.6980087e-03 -1.0342204e-03 -5.2042734e-03  6.5792515e-03\n",
            "  8.7828115e-03 -7.4120974e-03  9.8055657e-03  7.3666479e-03\n",
            " -7.4607255e-03 -1.8999577e-03  4.2520380e-03  7.0596053e-03\n",
            " -3.6636866e-03 -6.9730817e-03  4.7248350e-03 -9.0386067e-03\n",
            " -5.8503030e-03 -1.2834811e-03  5.4809176e-03 -5.6869411e-03\n",
            "  4.7847857e-03 -4.3494583e-04  2.6672638e-03  6.4039291e-03\n",
            "  1.4176309e-03  7.7085746e-03 -3.2240152e-04 -8.2637034e-03\n",
            "  9.1784988e-03 -4.8582028e-03  4.7219060e-03 -3.9027834e-03\n",
            " -7.3295189e-03 -6.5126489e-03  4.6773339e-03 -6.5943244e-04\n",
            "  1.4602697e-03 -8.9282785e-03 -5.1465523e-03 -6.0544228e-03\n",
            "  8.4127877e-03 -8.6974325e-03  5.0248443e-03 -8.6135149e-04\n",
            "  1.8937707e-04  8.7997578e-03 -3.5854375e-03 -6.9373380e-03\n",
            "  7.6357962e-04  7.7428352e-03  9.1208639e-03 -3.6847114e-03\n",
            "  2.7328073e-03  4.9426113e-03 -5.2920487e-03  6.8525351e-03\n",
            " -6.4529707e-03  2.1008432e-03  4.5872582e-03  4.3851123e-03\n",
            " -4.6662842e-03  2.6424218e-03  7.3099639e-03  8.6116884e-03\n",
            " -9.5125306e-03  5.5747475e-03  4.9680639e-03 -1.5947580e-03\n",
            "  9.1868844e-03 -4.1810106e-03 -1.7487227e-03 -6.8633081e-03\n",
            " -3.7766756e-03  2.4267554e-04 -3.2715332e-03 -5.4172636e-03\n",
            "  6.5688742e-03 -5.3028557e-03 -6.3216304e-03  7.6409671e-03\n",
            "  9.6511841e-03  3.9949189e-03  2.6326179e-05  7.8929187e-04\n",
            " -9.6155284e-04  6.8626525e-03 -6.2529948e-03  5.0760986e-04\n",
            "  4.2921496e-03 -2.1114135e-03  8.9388253e-04  3.7101412e-03\n",
            "  9.7100530e-03  2.1757602e-03  9.5001627e-03 -5.8298432e-03]\n",
            "\n",
            "CBOW Model - Most similar words to 'language':\n",
            "[('vector', 0.23780490458011627), ('word2vec', 0.15624567866325378), ('tends', 0.15600773692131042), ('natural', 0.14895176887512207), ('is', 0.10849117487668991), ('more', 0.10184375941753387), ('and', 0.08061150461435318), ('relationships', 0.06336083263158798), ('capture', 0.047527607530355453), ('to', 0.04717731475830078)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Skip-gram**\n",
        "\n",
        "Skip-gram predicts the context from a given word. It can be used by setting `sg=1` in `gensim.models.Word2Vec()`"
      ],
      "metadata": {
        "id": "xmiZoe3p9PIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------\n",
        "# Option 2: Train a Word2Vec model using Skip-gram (sg=1)\n",
        "# ---------------------\n",
        "skipgram_model = Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=100,    # Dimensionality of word vectors\n",
        "    window=5,           # Maximum distance between current and predicted word\n",
        "    sg=1,               # Skip-gram architecture\n",
        "    min_count=1,        # Ignore words with frequency < min_count\n",
        "    workers=2           # Number of CPU threads\n",
        ")\n",
        "\n",
        "print(\"Skip-gram Vector for 'language':\")\n",
        "print(skipgram_model.wv['language'])\n",
        "\n",
        "print(\"\\nSkip-gram Model - Most similar words to 'language':\")\n",
        "print(skipgram_model.wv.most_similar(\"language\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ7_YMc9vQ67",
        "outputId": "c7480265-c247-4fde-85ce-83373eca219c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skip-gram Vector for 'language':\n",
            "[ 6.4154328e-03 -8.9511415e-03 -7.3454725e-03 -1.7511440e-03\n",
            "  1.6980087e-03 -1.0342204e-03 -5.2042734e-03  6.5792515e-03\n",
            "  8.7828115e-03 -7.4120974e-03  9.8055657e-03  7.3666479e-03\n",
            " -7.4607255e-03 -1.8999577e-03  4.2520380e-03  7.0596053e-03\n",
            " -3.6636866e-03 -6.9730817e-03  4.7248350e-03 -9.0386067e-03\n",
            " -5.8503030e-03 -1.2834811e-03  5.4809176e-03 -5.6869411e-03\n",
            "  4.7847857e-03 -4.3494583e-04  2.6672638e-03  6.4039291e-03\n",
            "  1.4176309e-03  7.7085746e-03 -3.2240152e-04 -8.2637034e-03\n",
            "  9.1784988e-03 -4.8582028e-03  4.7219060e-03 -3.9027834e-03\n",
            " -7.3295189e-03 -6.5126489e-03  4.6773339e-03 -6.5943244e-04\n",
            "  1.4602697e-03 -8.9282785e-03 -5.1465523e-03 -6.0544228e-03\n",
            "  8.4127877e-03 -8.6974325e-03  5.0248443e-03 -8.6135149e-04\n",
            "  1.8937707e-04  8.7997578e-03 -3.5854375e-03 -6.9373380e-03\n",
            "  7.6357962e-04  7.7428352e-03  9.1208639e-03 -3.6847114e-03\n",
            "  2.7328073e-03  4.9426113e-03 -5.2920487e-03  6.8525351e-03\n",
            " -6.4529707e-03  2.1008432e-03  4.5872582e-03  4.3851123e-03\n",
            " -4.6662842e-03  2.6424218e-03  7.3099639e-03  8.6116884e-03\n",
            " -9.5125306e-03  5.5747475e-03  4.9680639e-03 -1.5947580e-03\n",
            "  9.1868844e-03 -4.1810106e-03 -1.7487227e-03 -6.8633081e-03\n",
            " -3.7766756e-03  2.4267554e-04 -3.2715332e-03 -5.4172636e-03\n",
            "  6.5688742e-03 -5.3028557e-03 -6.3216304e-03  7.6409671e-03\n",
            "  9.6511841e-03  3.9949189e-03  2.6326179e-05  7.8929187e-04\n",
            " -9.6155284e-04  6.8626525e-03 -6.2529948e-03  5.0760986e-04\n",
            "  4.2921496e-03 -2.1114135e-03  8.9388253e-04  3.7101412e-03\n",
            "  9.7100530e-03  2.1757602e-03  9.5001627e-03 -5.8298432e-03]\n",
            "\n",
            "Skip-gram Model - Most similar words to 'language':\n",
            "[('vector', 0.23781229555606842), ('word2vec', 0.15633781254291534), ('tends', 0.15600773692131042), ('natural', 0.14895176887512207), ('is', 0.10854827612638474), ('more', 0.10184375941753387), ('and', 0.08059525489807129), ('relationships', 0.06336083263158798), ('capture', 0.047527607530355453), ('to', 0.04717731475830078)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Word Embeddings using Word2Vec on 'text8' Corpus**\n",
        "\n",
        "Use [Gensim Downloader API](https://radimrehurek.com/gensim/downloader.html) to load `text8` corpus"
      ],
      "metadata": {
        "id": "x5TdK4uaG8JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a preprocessed Wikipedia dataset 'text8'\n",
        "dataset = api.load(\"text8\")\n",
        "sentences = list(dataset)\n"
      ],
      "metadata": {
        "id": "HXGvpyxbPSf8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Number of CPU cores\n",
        "print(\"CPU Cores:\")\n",
        "!grep -c '^processor' /proc/cpuinfo"
      ],
      "metadata": {
        "id": "fBJ9eXboPUKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3856c11f-5a86-4603-f033-337273b0256f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Cores:\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = sentences\n",
        "# Train a Word2Vec model using CBOW\n",
        "cbow_model = Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=100,    # Dimensionality of word vectors\n",
        "    window=5,           # Maximum distance between current and predicted word\n",
        "    sg=0,               # CBOW architecture (default)\n",
        "    min_count=1,        # Ignore words with frequency < min_count\n",
        "    workers=2           # Number of CPU threads\n",
        ")"
      ],
      "metadata": {
        "id": "YJbpxwqZPnz9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Predict top 3 similar words to 'king', using the trained Word2Vec model\n",
        "print(\"CBOW Vector for 'king':\")\n",
        "print(cbow_model.wv['king'])\n",
        "\n",
        "print(\"\\nCBOW Model - Top 3 similar words to 'king':\")\n",
        "print(cbow_model.wv.most_similar(\"king\", topn=3))"
      ],
      "metadata": {
        "id": "qb1U-olXPqaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1cecfb-ea05-4429-9f04-d9978b46607b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBOW Vector for 'king':\n",
            "[-2.1695945   0.5847411   3.2021227   0.2976922   2.3323178   1.5003363\n",
            "  2.4373105   0.2977524   0.4758191   0.17675078 -3.4745905  -2.9144578\n",
            " -0.68318254  5.86263    -2.0450642   0.09799168  1.3985769  -0.35918367\n",
            "  1.4730158   0.26482123 -0.70288175  2.0615118  -1.7213688   0.08982217\n",
            " -0.19036348  0.5005349  -1.4481603   1.0729766   0.696614   -1.2911931\n",
            " -1.1185753   0.34417343  1.970582    0.05067883  2.7318215   1.0668592\n",
            "  0.37994498 -2.0603201  -0.31645995 -2.006795   -1.6716607  -0.8880612\n",
            " -1.2657269  -0.88274217 -4.392502   -0.6589444  -1.21468     3.3773243\n",
            "  3.1391618  -0.736303    3.302079    0.7741737  -1.6376418   2.6328306\n",
            " -0.80173177 -1.5870308  -0.8007671   1.2712377   1.4984668  -0.5695333\n",
            "  1.4345889   0.3421586   0.9933981   0.62779355  0.73089826  0.36383626\n",
            " -2.4109068   1.8112689   1.3038373  -1.6203868  -0.10327034  0.12920262\n",
            " -0.60925305 -2.1789649   1.7843876  -1.9788699   0.07465937  2.159091\n",
            " -2.9001215   3.0305536  -1.2490788  -2.9412212  -0.9269043   1.1907806\n",
            " -2.9917693   1.853553    0.24964626 -1.0593776  -3.0909092   0.73984236\n",
            "  1.8229746   1.0693427  -0.8284192  -1.44849     2.703783   -1.1930083\n",
            "  3.5474734   2.5277584  -2.1619258  -1.6448016 ]\n",
            "\n",
            "CBOW Model - Top 3 similar words to 'king':\n",
            "[('prince', 0.7378984689712524), ('queen', 0.7250439524650574), ('emperor', 0.7210273742675781)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Perform Word algebra (king - man + woman = ?), using the trained Word2Vec model\n",
        "result = cbow_model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=3)\n",
        "\n",
        "# Top results\n",
        "for word, similarity in result:\n",
        "    print(f\"{word}: {similarity:.4f}\")"
      ],
      "metadata": {
        "id": "SaXUkPSNPsGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180b803c-59d4-40a9-d1c8-0e4b6309a787"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen: 0.6931\n",
            "daughter: 0.6605\n",
            "empress: 0.6570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Global Vectors for Word Representation (GloVe)**\n"
      ],
      "metadata": {
        "id": "o_avWrkB8-uT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GLoVe model (Wikipedia + Gigaword corpus)\n",
        "glove = api.load(\"glove-twitter-25\")  # 25-dimensional vectors\n",
        "\n",
        "# Similarity check\n",
        "print(glove.most_similar(\"computer\", topn=3))\n",
        "\n",
        "print(glove['computer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f37aaf-d9cb-491f-92d1-83274276c544",
        "id": "xthA00KxC1TH"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('camera', 0.907833456993103), ('cell', 0.891890287399292), ('server', 0.874466598033905)]\n",
            "[ 0.64005  -0.019514  0.70148  -0.66123   1.1723   -0.58859   0.25917\n",
            " -0.81541   1.1708    1.1413   -0.15405  -0.11369  -3.8414   -0.87233\n",
            "  0.47489   1.1541    0.97678   1.1107   -0.14572  -0.52013  -0.52234\n",
            " -0.92349   0.34651   0.061939 -0.57375 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Word Embeddings using GloVe**"
      ],
      "metadata": {
        "id": "mWFdPPblGiTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GLoVe model (Wikipedia + Gigaword corpus)\n",
        "dataset = api.load(\"glove-wiki-gigaword-300\")\n",
        "\n",
        "# 1. Predict top 3 similar words to 'king'\n",
        "print(\"Top 3 similar words to king \\n\", glove.most_similar(\"king\", topn=3))\n",
        "\n",
        "# 2. Word analogy: king - man + woman = ?\n",
        "# Perform word analogy: king - man + woman = ?\n",
        "result = glove.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)\n",
        "print(\"Word analogy: king - man + woman = \", result[0][0])\n",
        "\n",
        "# 3. Get Vector for any word and Print it\n",
        "print(\"Vector for 'king':\")\n",
        "print(glove['king'])"
      ],
      "metadata": {
        "id": "iT-FjDR8PH0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a329bd-9cef-4b4a-db1a-85bcc92f1f87"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 similar words to king \n",
            " [('prince', 0.9337409734725952), ('queen', 0.9202421307563782), ('aka', 0.9176921844482422)]\n",
            "Word analogy: king - man + woman =  meets\n",
            "Vector for 'king':\n",
            "[-0.74501  -0.11992   0.37329   0.36847  -0.4472   -0.2288    0.70118\n",
            "  0.82872   0.39486  -0.58347   0.41488   0.37074  -3.6906   -0.20101\n",
            "  0.11472  -0.34661   0.36208   0.095679 -0.01765   0.68498  -0.049013\n",
            "  0.54049  -0.21005  -0.65397   0.64556 ]\n"
          ]
        }
      ]
    }
  ]
}